[train]
# auto_N: Select and lock N free GPUs
#      N: Use Nth GPU
#  0,1,N: Use GPUs numbered 0,1 and N
# (Multi-GPU options are there but not implemented yet in
#  training logic.)
device_id: auto_1

# Print info to screen and log file each `disp_freq` minibatches
disp_freq: 30

# If > 0, the seed will be fixed for reproducibility
seed: 0

# A `model_type` should be the class name of the model you'd like to train
# See nmtpytorch/models/
model_type: NMT

# After this many validations without improvement, the training will stop.
patience: 5

# The training will stop after this many epochs
max_epochs: 100

# Same as above but in terms of mini-batch count
max_iterations: 1000000

# An evaluation on held-out `val_set` will be performed
# after each `eval_freq` minibatches
eval_freq: 0

# Evaluate on validation set once before starting training
eval_zero: False

# Validation warmup. No periodic evaluation
# will be performed before epoch `eval_start` is reached.
eval_start: 5

# One or many evaluation metrics for held-out evaluation
# Early-stopping criterion is always the first one
eval_metrics: meteor,bleu,loss

# Post-processing filters to apply to beam-search outputs and references
# in order to correctly compute metrics (check: nmtpytorch/filters.py)
eval_filters: de-bpe

# Beam size during evaluation
eval_beam: 12

# Batch size for batched beam-search on GPU
eval_batch_size: 12

# Save the best model w.r.t each metric provided in `eval_metrics`
save_best_metrics: True


# Saves a snapshot every `checkpoint_freq` minibatches
checkpoint_freq: 3000

# Keeps a rolling buffer of `n_checkpoints` for periodic checkpointing
n_checkpoints: 2

# Scaling factor for L2 regularization
#l2_reg: 1e-5

# Gradient clipping norm
gclip: 1


# Optimizers from PyTorch (in lowercase)
optimizer: adam

# Initial learning rate for the above optimizer (0 uses PyTorch' defaults)
lr: 0.0004
lr_decay: plateau
lr_decay_revert: False
lr_decay_factor: 0.5
lr_decay_patience: 2

# Training batch_size. Same is used for evaluation loss batching.
batch_size: 32

# Where to save the models
save_path: ./models

# If given and TensorbardX is installed, TensorBoard files will be
# stored under this folder.
tensorboard_dir: ${save_path}/tb_dir

##################################################################
# Below section is completely dependent on the model_type selected
# The defaults for these arguments are defined in the relevant
# nmtpytorch/models/<model.py>
##################################################################

[model]
max_len = 80

# type of attention: mlp/dot (dot is untested)
att_type: mlp

# number of encoder layers
n_encoders: 1


# Encoder is a bi-directional GRU with enc_dim units
enc_dim: 512

# Decoder is a 2-layer GRU (CGRU) with dec_dim units
dec_dim: 512

# CGRU decoder initialization
#   mean_ctx: h_0 = W_decinit.dot(tanh(mean(encoder states)))
#       zero: h_0 = 0
dec_init: mean_ctx

# Both source/target embeddings are <emb_dim>-dimensional
emb_dim: 256

# 2-way: Shares input/output embeddings of decoder i.e. target-side
# 3-way: 2-way + source embedding sharing
#        this requires **same** vocabularies
#        Check -s argument of nmtpy-build-vocab
# False: disabled.
tied_emb: 2way

# If n_encoders > 1, defines the dropout between encoder layers
dropout_emb_enc: 0.3
dropout_emb_dec: 0.0
dropout_enc: 0.0
dropout_dec: 0.0
dropout_out: 0.5
dropout_ctx: 0.5


# Trains an NMT from en->de
# This automatically take cares of determining src->trg order for
# the below data files. You can just change this to de->en to train
# another NMT for the inverse direction.
direction: en:Text,image:Numpy -> de:Text

#############################
# Here we define the datasets
#############################
[data]
# A placeholder for data root
root: ./data/

train_set: {'en': '${root}/data.tok.bpe/train.lc.norm.tok.bpe.en',
            'image': '${root}/image_splits/train/train-resnet50-avgpool-r224-c224.npy',
            'de': '${root}/data.tok.bpe/train.lc.norm.tok.bpe.de'}

val_set: {'en': '${root}/data.tok.bpe/val.lc.norm.tok.bpe.en',
          'image': '${root}/image_splits/val/val-resnet50-avgpool-r224-c224.npy',
          'de': '${root}/data.tok.bpe/val.lc.norm.tok.bpe.de'}


test_2016_flickr_set: {'en': '${root}/data.tok.bpe/test_2016_flickr.lc.norm.tok.bpe.en',
                       'image': '${root}/image_splits/test_2016_flickr/test_2016_flickr-resnet50-avgpool-r224-c224.npy',
                       'de': '${root}/data.tok.bpe/test_2016_flickr.lc.norm.tok.bpe.de'}

test_2017_flickr_set: {'en': '${root}/data.tok.bpe/test_2017_flickr.lc.norm.tok.bpe.en',
                       'image': '${root}/image_splits/test_2017_flickr/test_2017_flickr-resnet50-avgpool-r224-c224.npy',
                       'de': '${root}/data.tok.bpe/test_2017_flickr.lc.norm.tok.bpe.de'}

test_2017_mscoco_set: {'en': '${root}/data.tok.bpe/test_2017_mscoco.lc.norm.tok.bpe.en',
                       'image': '${root}/image_splits/test_2017_mscoco/test_2017_mscoco-resnet50-avgpool-r224-c224.npy',
                       'de': '${root}/data.tok.bpe/test_2017_mscoco.lc.norm.tok.bpe.de'}

test_2018_flickr_set: {'en': '${root}/data.tok.bpe/test_2018_flickr.lc.norm.tok.bpe.en',
                       'image': '${root}/image_splits/test_2018_flickr/test_2018_flickr-resnet50-avgpool-r224-c224.npy',
                       'de': '${root}/data.tok.bpe/test_2018_flickr.lc.norm.tok.bpe.de'}

###############################################
# Vocabulary files created by nmtpy-build-vocab
# one per each language key
###############################################
[vocabulary]
en: ${data:root}/data.tok.bpe/train.lc.norm.tok.bpe.vocab.en
de: ${data:root}/data.tok.bpe/train.lc.norm.tok.bpe.vocab.de